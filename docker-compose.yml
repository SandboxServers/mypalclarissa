services:
  # PostgreSQL databases
  postgres:
    image: postgres:16
    container_name: mypalclara-postgres
    environment:
      POSTGRES_USER: clara
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-clara}
      POSTGRES_DB: clara_main
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U clara -d clara_main"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  postgres-vectors:
    image: pgvector/pgvector:pg16
    container_name: mypalclara-postgres-vectors
    environment:
      POSTGRES_USER: clara
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-clara}
      POSTGRES_DB: clara_vectors
    volumes:
      - postgres-vectors-data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U clara -d clara_vectors"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  backend:
    image: ${REGISTRY:-}mypalclara-backend:latest
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mypalclara-backend
    profiles:
      - backend
      - full
    ports:
      - "8000:8000"
    environment:
      # LLM Provider
      - LLM_PROVIDER=${LLM_PROVIDER:-openrouter}
      # OpenRouter (when LLM_PROVIDER=openrouter)
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-sonnet-4}
      - OPENROUTER_SITE=${OPENROUTER_SITE:-http://localhost:3000}
      - OPENROUTER_TITLE=${OPENROUTER_TITLE:-MyPalClara}
      # NanoGPT (when LLM_PROVIDER=nanogpt)
      - NANOGPT_API_KEY=${NANOGPT_API_KEY}
      - NANOGPT_MODEL=${NANOGPT_MODEL:-moonshotai/Kimi-K2-Instruct-0905}
      - NANOGPT_MEM0_MODEL=${NANOGPT_MEM0_MODEL:-openai/gpt-oss-120b}
      # Custom OpenAI (when LLM_PROVIDER=openai)
      - CUSTOM_OPENAI_API_KEY=${CUSTOM_OPENAI_API_KEY:-}
      - CUSTOM_OPENAI_BASE_URL=${CUSTOM_OPENAI_BASE_URL:-https://api.openai.com/v1}
      - CUSTOM_OPENAI_MODEL=${CUSTOM_OPENAI_MODEL:-gpt-4o}
      # OpenAI (for embeddings)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # PostgreSQL (hardcoded for Docker - ignores .env localhost values)
      - DATABASE_URL=postgresql://clara:${POSTGRES_PASSWORD:-clara}@postgres:5432/clara_main
      - MEM0_DATABASE_URL=postgresql://clara:${POSTGRES_PASSWORD:-clara}@postgres-vectors:5432/clara_vectors
      # Mem0 Provider
      - MEM0_PROVIDER=${MEM0_PROVIDER:-openrouter}
      - MEM0_MODEL=${MEM0_MODEL:-openai/gpt-4o-mini}
      # User config
      - USER_ID=${USER_ID:-demo-user}
      - DEFAULT_PROJECT=${DEFAULT_PROJECT:-Default Project}
    volumes:
      - mypalclara-data:/data
      - ./inputs/user_profile.txt:/app/inputs/user_profile.txt:ro
      - ./personality.txt:/app/personality.txt:ro
    depends_on:
      postgres:
        condition: service_healthy
      postgres-vectors:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  frontend:
    image: ${REGISTRY:-}mypalclara-frontend:latest
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: mypalclara-frontend
    profiles:
      - frontend
      - full
    ports:
      - "3000:3000"
    environment:
      # LLM Provider
      - LLM_PROVIDER=${LLM_PROVIDER:-openrouter}
      # OpenRouter (when LLM_PROVIDER=openrouter)
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-sonnet-4}
      - OPENROUTER_SITE=${OPENROUTER_SITE:-http://localhost:3000}
      - OPENROUTER_TITLE=${OPENROUTER_TITLE:-MyPalClara}
      # NanoGPT (when LLM_PROVIDER=nanogpt)
      - NANOGPT_API_KEY=${NANOGPT_API_KEY}
      - NANOGPT_MODEL=${NANOGPT_MODEL:-moonshotai/Kimi-K2-Instruct-0905}
      # Backend URL (server-side, internal Docker network)
      - BACKEND_URL=http://backend:8000
      # OpenAI (for embeddings - if needed)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    restart: unless-stopped

  # Discord bot (optional - run with: docker-compose --profile discord up)
  discord-bot:
    image: ${REGISTRY:-}mypalclara-discord:latest
    build:
      context: .
      dockerfile: Dockerfile.discord
    container_name: mypalclara-discord
    profiles:
      - discord
    ports:
      - "8001:8001"  # Monitor dashboard
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Access host services (clewdr, etc.)
    environment:
      # Discord
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - DISCORD_CLIENT_ID=${DISCORD_CLIENT_ID:-}
      - DISCORD_ALLOWED_CHANNELS=${DISCORD_ALLOWED_CHANNELS:-}
      - DISCORD_ALLOWED_ROLES=${DISCORD_ALLOWED_ROLES:-}
      - DISCORD_MAX_MESSAGES=${DISCORD_MAX_MESSAGES:-25}
      # Bot personality
      - BOT_NAME=${BOT_NAME:-Clara}
      - BOT_PERSONALITY_FILE=${BOT_PERSONALITY_FILE:-personality.txt}
      # Organic responses
      - ORGANIC_RESPONSE_ENABLED=${ORGANIC_RESPONSE_ENABLED:-false}
      - ORGANIC_CONFIDENCE_THRESHOLD=${ORGANIC_CONFIDENCE_THRESHOLD:-0.7}
      - ORGANIC_COOLDOWN_MINUTES=${ORGANIC_COOLDOWN_MINUTES:-5}
      - ORGANIC_DAILY_LIMIT=${ORGANIC_DAILY_LIMIT:-50}
      # LLM Provider
      - LLM_PROVIDER=${LLM_PROVIDER:-openrouter}
      # OpenRouter
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-anthropic/claude-sonnet-4}
      # NanoGPT
      - NANOGPT_API_KEY=${NANOGPT_API_KEY:-}
      - NANOGPT_MODEL=${NANOGPT_MODEL:-moonshotai/Kimi-K2-Instruct-0905}
      # Custom OpenAI (when LLM_PROVIDER=openai)
      - CUSTOM_OPENAI_API_KEY=${CUSTOM_OPENAI_API_KEY:-}
      - CUSTOM_OPENAI_BASE_URL=${CUSTOM_OPENAI_BASE_URL:-https://api.openai.com/v1}
      - CUSTOM_OPENAI_MODEL=${CUSTOM_OPENAI_MODEL:-gpt-4o}
      # Tool calling (set TOOL_FORMAT=claude for Claude proxies like clewdr)
      - TOOL_API_KEY=${TOOL_API_KEY:-}
      - TOOL_BASE_URL=${TOOL_BASE_URL:-}
      - TOOL_MODEL=${TOOL_MODEL:-}
      - TOOL_FORMAT=${TOOL_FORMAT:-openai}
      # OpenAI (for embeddings)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # PostgreSQL (hardcoded for Docker - ignores .env localhost values)
      - DATABASE_URL=postgresql://clara:${POSTGRES_PASSWORD:-clara}@postgres:5432/clara_main
      - MEM0_DATABASE_URL=postgresql://clara:${POSTGRES_PASSWORD:-clara}@postgres-vectors:5432/clara_vectors
      # Mem0 Provider
      - MEM0_PROVIDER=${MEM0_PROVIDER:-openrouter}
      - MEM0_MODEL=${MEM0_MODEL:-openai/gpt-4o-mini}
      # Web search
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
      # User config
      - USER_ID=${USER_ID:-demo-user}
      - DEFAULT_PROJECT=${DEFAULT_PROJECT:-Default Project}
      # Monitor
      - DISCORD_MONITOR_PORT=8001
      - DISCORD_MONITOR_ENABLED=${DISCORD_MONITOR_ENABLED:-true}
      # Email (optional)
      - CLARA_EMAIL_ADDRESS=${CLARA_EMAIL_ADDRESS:-}
      - CLARA_EMAIL_PASSWORD=${CLARA_EMAIL_PASSWORD:-}
      - CLARA_EMAIL_NOTIFY_USER=${CLARA_EMAIL_NOTIFY_USER:-}
      - CLARA_EMAIL_NOTIFY=${CLARA_EMAIL_NOTIFY:-false}
      # API URL for dashboard cross-service stats (optional)
      - API_URL=http://backend:8000
      # Graph memory (optional)
      - ENABLE_GRAPH_MEMORY=${ENABLE_GRAPH_MEMORY:-false}
      - GRAPH_STORE_PROVIDER=${GRAPH_STORE_PROVIDER:-neo4j}
      - NEO4J_URL=${NEO4J_URL:-}
      - NEO4J_USERNAME=${NEO4J_USERNAME:-}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-}
      # Fast LLM (for quick operations)
      - FAST_LLM_PROVIDER=${FAST_LLM_PROVIDER:-}
      - FAST_LLM_MODEL=${FAST_LLM_MODEL:-}
      # E2B sandbox (alternative to Docker)
      - E2B_API_KEY=${E2B_API_KEY:-}
      - E2B_TIMEOUT=${E2B_TIMEOUT:-300}
      # S3 storage (optional)
      - S3_ENABLED=${S3_ENABLED:-false}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-}
      - S3_BUCKET=${S3_BUCKET:-}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY:-}
      - S3_SECRET_KEY=${S3_SECRET_KEY:-}
      - S3_REGION=${S3_REGION:-}
      # General
      - SKIP_PROFILE_LOAD=true
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - mypalclara-data:/data
      - mypalclara-files:/app/clara_files
      - /var/run/docker.sock:/var/run/docker.sock  # For Docker sandbox
      - ./inputs/user_profile.txt:/app/inputs/user_profile.txt:ro
      - ./personality.txt:/app/personality.txt:ro
    depends_on:
      postgres:
        condition: service_healthy
      postgres-vectors:
        condition: service_healthy
    restart: unless-stopped

volumes:
  mypalclara-data:
  mypalclara-files:
  postgres-data:
  postgres-vectors-data:

networks:
  default:
    name: mypalclara-network
